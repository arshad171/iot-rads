{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import keras network elements\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import (\n",
    "    Multiply,\n",
    "    Add,\n",
    "    Rescaling,\n",
    "    ZeroPadding2D,\n",
    "    Lambda,\n",
    "    Conv2D,\n",
    "    DepthwiseConv2D,\n",
    "    ReLU,\n",
    "    MaxPooling2D,\n",
    "    BatchNormalization,\n",
    "    GlobalAveragePooling2D,\n",
    "    Reshape,\n",
    "    Layer,\n",
    "    Dense,\n",
    "    Input,\n",
    "    multiply\n",
    ")\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Import Keras preprocessing facilities\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Import MobileNet models\n",
    "from keras.applications import MobileNetV3Small,MobileNetV3Large\n",
    "from keras.applications.mobilenet_v3 import preprocess_input, decode_predictions\n",
    "import tensorflow_model_optimization as tfmot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here for testing purposes\n",
    "def representative_dataset_gen():\n",
    "    for _ in range(100):\n",
    "        yield [np.random.rand(1,240,320,1).astype(np.float32)]\n",
    "\n",
    "def save_model(converter, basename: str):\n",
    "    # Save the .tfmodel first\n",
    "    content = converter.convert()\n",
    "    with open(f\"{basename}.tflite\",\"wb\") as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    # Convert the model to a C array\n",
    "    with open(f\"{basename}.h\", 'w') as f:\n",
    "        f.write(\"const unsigned char model_data[] = {\" + \",\".join([f\"0x{byte:02x}\" for byte in content]) + \"};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_annotate (Quantiz  (None, 80, 107, 4)        104       \n",
      " eAnnotate)                                                      \n",
      "                                                                 \n",
      " quantize_annotate_1 (Quant  (None, 80, 107, 4)        0         \n",
      " izeAnnotate)                                                    \n",
      "                                                                 \n",
      " quantize_annotate_2 (Quant  (None, 80, 107, 12)       780       \n",
      " izeAnnotate)                                                    \n",
      "                                                                 \n",
      " quantize_annotate_3 (Quant  (None, 80, 107, 12)       48        \n",
      " izeAnnotate)                                                    \n",
      "                                                                 \n",
      " quantize_annotate_4 (Quant  (None, 80, 107, 12)       0         \n",
      " izeAnnotate)                                                    \n",
      "                                                                 \n",
      " quantize_annotate_5 (Quant  (None, 12)                0         \n",
      " izeAnnotate)                                                    \n",
      "                                                                 \n",
      " quantize_annotate_6 (Quant  (None, 100)               1300      \n",
      " izeAnnotate)                                                    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2232 (8.72 KB)\n",
      "Trainable params: 2208 (8.62 KB)\n",
      "Non-trainable params: 24 (96.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "quantized = tfmot.quantization.keras.quantize_annotate_layer\n",
    "\n",
    "quantized_model = Sequential([\n",
    "        quantized(Conv2D(4, (5, 5), strides=(3, 3), padding='same', activation=None, input_shape=(240, 320, 1))),\n",
    "        quantized(ReLU()),\n",
    "        quantized(Conv2D(12, (4, 4), padding='same', activation=None)),\n",
    "        quantized(BatchNormalization()),\n",
    "        quantized(ReLU()),\n",
    "        quantized(GlobalAveragePooling2D()),\n",
    "\n",
    "        quantized(Dense(100, activation='relu'))\n",
    "])\n",
    "\n",
    "quantized_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_quantized_model = Sequential([\n",
    "        Conv2D(4, (5, 5), strides=(3, 3), padding='same', activation=None, input_shape=(240, 320, 1)),\n",
    "        ReLU(),\n",
    "        Conv2D(12, (4, 4), padding='same', activation=None),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        GlobalAveragePooling2D(),\n",
    "\n",
    "        Dense(100, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 128 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 51ms/step - loss: 1.0415\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.0019\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.9937\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.9903\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.9885\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.9861\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.9841\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.9822\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.9815\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.9798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x191743a6950>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_folder_path = '../trainlib/'\n",
    "\n",
    "# Load the images as a dataset\n",
    "# You can specify the image size, batch size, and other parameters as needed\n",
    "image_size = (240, 320)  # Set the size of your images\n",
    "batch_size = 32  # Number of images to process at a time\n",
    "\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    image_folder_path,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "dataset = dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "\n",
    "non_quantized_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "non_quantized_model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Blake\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "non_quantized_model.save('working.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Blake\\AppData\\Local\\Temp\\tmptqj8mukr\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Blake\\AppData\\Local\\Temp\\tmptqj8mukr\\assets\n",
      "c:\\Users\\Blake\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:947: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Model_to_convert = non_quantized_model\n",
    "\n",
    "\n",
    "# Convert the model to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(Model_to_convert)\n",
    "\n",
    "# Setup converter optimizations\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Restrain the available operations and set the desired data types\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] # All layers must use 8-bit operations\n",
    "converter.inference_input_type = tf.int8                                    # Input is UINT8 (image data, 0-255)\n",
    "converter.inference_output_type = tf.float32                                # Output is supposed to be float32\n",
    "\n",
    "# Build the representative dataset\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "\n",
    "# Convert and save the model\n",
    "save_model(converter,\"working\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model on a picture from our Testing Dataset\n",
    "\n",
    "We perform prediction using our selected model and obtain the feature vector. This is useful to cross-check the results we get from the Arduino and the distributed learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "feature vector: [[ 9.442699    5.302475    0.          0.          2.0050862   5.2273526\n",
      "   1.9076254   0.          0.          7.533764    0.         15.076152\n",
      "   0.          0.36931926  0.          0.          0.         12.06289\n",
      "   2.907904    0.          2.3004632   0.          1.4628525   0.\n",
      "   4.422877    0.5961104   9.192916    0.3921283   0.07196429  0.\n",
      "   3.0060604   9.682591    7.0994124   0.          5.856418    1.3322003\n",
      "   0.          0.          3.6338456   0.          0.          0.\n",
      "   4.889263    0.82927424 10.199273    0.          8.563771    0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   5.8622146   0.          0.33981398  0.          5.9617314   5.2294292\n",
      "   0.          3.7462883   0.         10.648001    6.656627    0.\n",
      "   3.5234249   0.          0.          1.0622663   0.          0.\n",
      "   0.          0.          0.          6.2285557   4.5131865   0.\n",
      "   0.          0.          3.5571074   1.9741532   8.416868    0.\n",
      "   5.6782813   4.478606   15.028632    5.0531244   0.          0.\n",
      "   0.          0.          0.          0.          2.3006244   0.\n",
      "   0.          2.2510433   1.7942027   1.6706513 ]]\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess an image\n",
    "img_path = '../images-data1/1-image-9.jpg'  # Replace with your image path\n",
    "img = image.load_img(img_path, color_mode='grayscale')\n",
    "img_array = image.img_to_array(img)\n",
    "#img_array = np.repeat(img_array, 3, axis=-1)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# Model prediction\n",
    "predictions = keras_model.predict(img_array)\n",
    "print(\"feature vector:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99992025]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Flatten the embeddings if they are not already 2D\n",
    "embedding1_flat = embedding1.reshape(1, -1)\n",
    "embedding2_flat = embedding2.reshape(1, -1)\n",
    "\n",
    "# Now, calculate the cosine similarity\n",
    "similarity = cosine_similarity(embedding1_flat, embedding2_flat)\n",
    "similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing using MobileNet v3\n",
    "\n",
    "We test the prediction performance using the shrunk version of MobileNet v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "keras_model = MobileNetV3Small(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "img_path = '../images-data1/2-image-40.jpg'\n",
    "img = image.load_img(img_path,color_mode='grayscale')  # Replace with your model's expected input size\n",
    "img_array = image.img_to_array(img)\n",
    "#img_array = np.repeat(img_array, 3, axis=-1)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "img_path2 = '../images-data1/2-image-6.jpg'\n",
    "img2 = image.load_img(img_path2,color_mode='grayscale')  # Replace with your model's expected input size\n",
    "img_array2 = image.img_to_array(img2)\n",
    "#img_array2 = np.repeat(img_array2, 3, axis=-1)\n",
    "img_array2 = np.expand_dims(img_array2, axis=0)\n",
    "img_array2 = preprocess_input(img_array2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "embedding1 = keras_model.predict(img_array)\n",
    "embedding2 = keras_model.predict(img_array2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing MobileNet v3\n",
    "\n",
    "We experimented with a custom and truncated version of MobileNet, however due to the intrinsic structure of the model we were unable to do so with satisfactory results while meeting the stringent requirements of the Nano 33 BLE platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)        [(None, None, None, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " rescaling_9 (Rescaling)     (None, None, None, 3)        0         ['input_9[0][0]']             \n",
      "                                                                                                  \n",
      " Conv (Conv2D)               (None, None, None, 16)       432       ['rescaling_9[0][0]']         \n",
      "                                                                                                  \n",
      " Conv/BatchNorm (BatchNorma  (None, None, None, 16)       64        ['Conv[0][0]']                \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.add_140 (TFOpLambd  (None, None, None, 16)       0         ['Conv/BatchNorm[0][0]']      \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " re_lu_229 (ReLU)            (None, None, None, 16)       0         ['tf.math.add_140[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_140 (TFOp  (None, None, None, 16)       0         ['re_lu_229[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multiply_97 (Multiply)      (None, None, None, 16)       0         ['Conv/BatchNorm[0][0]',      \n",
      "                                                                     'tf.math.multiply_140[0][0]']\n",
      "                                                                                                  \n",
      " expanded_conv/depthwise/pa  (None, None, None, 16)       0         ['multiply_97[0][0]']         \n",
      " d (ZeroPadding2D)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise (D  (None, None, None, 16)       144       ['expanded_conv/depthwise/pad[\n",
      " epthwiseConv2D)                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise/Ba  (None, None, None, 16)       64        ['expanded_conv/depthwise[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " re_lu_230 (ReLU)            (None, None, None, 16)       0         ['expanded_conv/depthwise/Batc\n",
      "                                                                    hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_exci  (None, 1, 1, 16)             0         ['re_lu_230[0][0]']           \n",
      " te/AvgPool (GlobalAverageP                                                                       \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_exci  (None, 1, 1, 8)              136       ['expanded_conv/squeeze_excite\n",
      " te/Conv (Conv2D)                                                   /AvgPool[0][0]']              \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_exci  (None, 1, 1, 8)              0         ['expanded_conv/squeeze_excite\n",
      " te/Relu (ReLU)                                                     /Conv[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_exci  (None, 1, 1, 16)             144       ['expanded_conv/squeeze_excite\n",
      " te/Conv_1 (Conv2D)                                                 /Relu[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.math.add_141 (TFOpLambd  (None, 1, 1, 16)             0         ['expanded_conv/squeeze_excite\n",
      " a)                                                                 /Conv_1[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_231 (ReLU)            (None, 1, 1, 16)             0         ['tf.math.add_141[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_141 (TFOp  (None, 1, 1, 16)             0         ['re_lu_231[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_exci  (None, None, None, 16)       0         ['re_lu_230[0][0]',           \n",
      " te/Mul (Multiply)                                                   'tf.math.multiply_141[0][0]']\n",
      "                                                                                                  \n",
      " expanded_conv/project (Con  (None, None, None, 16)       256       ['expanded_conv/squeeze_excite\n",
      " v2D)                                                               /Mul[0][0]']                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " expanded_conv/project/Batc  (None, None, None, 16)       64        ['expanded_conv/project[0][0]'\n",
      " hNorm (BatchNormalization)                                         ]                             \n",
      "                                                                                                  \n",
      " expanded_conv_1/expand (Co  (None, None, None, 72)       1152      ['expanded_conv/project/BatchN\n",
      " nv2D)                                                              orm[0][0]']                   \n",
      "                                                                                                  \n",
      " expanded_conv_1/expand/Bat  (None, None, None, 72)       288       ['expanded_conv_1/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " re_lu_232 (ReLU)            (None, None, None, 72)       0         ['expanded_conv_1/expand/Batch\n",
      "                                                                    Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise/  (None, None, None, 72)       0         ['re_lu_232[0][0]']           \n",
      " pad (ZeroPadding2D)                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise   (None, None, None, 72)       648       ['expanded_conv_1/depthwise/pa\n",
      " (DepthwiseConv2D)                                                  d[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise/  (None, None, None, 72)       288       ['expanded_conv_1/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " re_lu_233 (ReLU)            (None, None, None, 72)       0         ['expanded_conv_1/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_1/project (C  (None, None, None, 24)       1728      ['re_lu_233[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_1/project/Ba  (None, None, None, 24)       96        ['expanded_conv_1/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_2/expand (Co  (None, None, None, 88)       2112      ['expanded_conv_1/project/Batc\n",
      " nv2D)                                                              hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_2/expand/Bat  (None, None, None, 88)       352       ['expanded_conv_2/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " re_lu_234 (ReLU)            (None, None, None, 88)       0         ['expanded_conv_2/expand/Batch\n",
      "                                                                    Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_2/depthwise   (None, None, None, 88)       792       ['re_lu_234[0][0]']           \n",
      " (DepthwiseConv2D)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_2/depthwise/  (None, None, None, 88)       352       ['expanded_conv_2/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " re_lu_235 (ReLU)            (None, None, None, 88)       0         ['expanded_conv_2/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_2/project (C  (None, None, None, 24)       2112      ['re_lu_235[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_2/project/Ba  (None, None, None, 24)       96        ['expanded_conv_2/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_2/Add (Add)   (None, None, None, 24)       0         ['expanded_conv_1/project/Batc\n",
      "                                                                    hNorm[0][0]',                 \n",
      "                                                                     'expanded_conv_2/project/Batc\n",
      "                                                                    hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_3/expand (Co  (None, None, None, 96)       2304      ['expanded_conv_2/Add[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " dense_36 (Dense)            (None, None, None, 100)      9700      ['expanded_conv_3/expand[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23324 (91.11 KB)\n",
      "Trainable params: 22492 (87.86 KB)\n",
      "Non-trainable params: 832 (3.25 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'expanded_conv_10/Add' is the layer before 'Conv_1'\n",
    "layer_name = 'expanded_conv_3/expand'\n",
    "new_base_model_output = keras_model.get_layer(layer_name).output\n",
    "\n",
    "# Create a new model\n",
    "new_model = Model(inputs=keras_model.input, outputs=new_base_model_output)\n",
    "\n",
    "new_output_layer = Dense(units=100, activation='relu')(new_model.output)  # Adjust units and activation as needed\n",
    "\n",
    "# Create a new model with the added Dense layer\n",
    "new_model = Model(inputs=new_model.input, outputs=new_output_layer)\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 240, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 240, 320, 16)         160       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 240, 320, 16)         64        ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)              (None, 240, 320, 16)         0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4  (None, 16)                   0         ['re_lu_8[0][0]']             \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " rescaling_3 (Rescaling)     (None, 16)                   0         ['global_average_pooling2d_4[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 4)                    68        ['rescaling_3[0][0]']         \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 16)                   80        ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " multiply (Multiply)         (None, 240, 320, 16)         0         ['re_lu_8[0][0]',             \n",
      "                                                                     'dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " depthwise_conv2d (Depthwis  (None, 240, 320, 16)         160       ['multiply[0][0]']            \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 240, 320, 16)         64        ['depthwise_conv2d[0][0]']    \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)              (None, 240, 320, 16)         0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 240, 320, 16)         272       ['re_lu_9[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 240, 320, 16)         64        ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)             (None, 240, 320, 16)         0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " depthwise_conv2d_1 (Depthw  (None, 240, 320, 16)         160       ['re_lu_10[0][0]']            \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 240, 320, 16)         64        ['depthwise_conv2d_1[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)             (None, 240, 320, 16)         0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 240, 320, 24)         408       ['re_lu_11[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 240, 320, 24)         96        ['conv2d_10[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)             (None, 240, 320, 24)         0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " depthwise_conv2d_2 (Depthw  (None, 120, 160, 24)         240       ['re_lu_12[0][0]']            \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 120, 160, 24)         96        ['depthwise_conv2d_2[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)             (None, 120, 160, 24)         0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 120, 160, 24)         600       ['re_lu_13[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 120, 160, 24)         96        ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)             (None, 120, 160, 24)         0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5  (None, 24)                   0         ['re_lu_14[0][0]']            \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 100)                  2500      ['global_average_pooling2d_5[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5192 (20.28 KB)\n",
      "Trainable params: 4920 (19.22 KB)\n",
      "Non-trainable params: 272 (1.06 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def squeeze_excite_block(input, ratio=4):\n",
    "    ''' Create a squeeze and excite block '''\n",
    "    filters = input.shape[-1]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(input)\n",
    "    se = Rescaling(1. / filters)(se)\n",
    "    se = Dense(filters // ratio, activation='relu')(se)\n",
    "    se = Dense(filters, activation='sigmoid')(se)\n",
    "\n",
    "    return Multiply()([input, se])\n",
    "\n",
    "def conv_block(inputs, filters, kernel_size, strides=1, padding='same'):\n",
    "    x = Conv2D(filters, kernel_size, strides=strides, padding=padding)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def depthwise_conv_block(inputs, pointwise_conv_filters, depth_multiplier=1, strides=1):\n",
    "    x = DepthwiseConv2D((3, 3), padding='same', depth_multiplier=depth_multiplier, strides=strides)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(pointwise_conv_filters, (1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "\n",
    "# Input layer\n",
    "inputs = Input(shape=(240, 320, 1))\n",
    "\n",
    "# First Convolution Block\n",
    "x = conv_block(inputs, 16, (3, 3))\n",
    "\n",
    "# Squeeze and Excitation block\n",
    "x = squeeze_excite_block(x)\n",
    "\n",
    "# Depthwise Convolution Blocks\n",
    "x = depthwise_conv_block(x, 16)\n",
    "x = depthwise_conv_block(x, 24)\n",
    "x = depthwise_conv_block(x, 24, strides=2)  # Assuming stride for downsampling\n",
    "\n",
    "# Add Global Average Pooling to flatten the output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Final dense layer\n",
    "output = Dense(100, activation='relu')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs, output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempting classification with 3 Classes\n",
    "\n",
    "We briefly experimented with 3-class classification:\n",
    "\n",
    "- Empty picture\n",
    "- Train/Tram\n",
    "- People\n",
    "\n",
    "The Arduino did not prove capable enough to run this larger and more complex model, so we abandoned the idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 128 files belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 8s 1s/step - loss: 5.7376 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 5.1411 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 4.7459 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 4.3947 - accuracy: 0.3750\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 4.0686 - accuracy: 0.8125\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 3.7440 - accuracy: 0.8828\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 3.4094 - accuracy: 0.8828\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 3.0339 - accuracy: 0.8828\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 2.6547 - accuracy: 0.8828\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 2.2627 - accuracy: 0.8828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19173c15f10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_folder_path = '../trainlib/'\n",
    "\n",
    "# Load the images as a dataset\n",
    "# You can specify the image size, batch size, and other parameters as needed\n",
    "image_size = (240, 320)  # Set the size of your images\n",
    "batch_size = 32  # Number of images to process at a time\n",
    "\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    image_folder_path,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size\n",
    ")\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "dataset = dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Blake\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('my_modelunsup.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
